{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import (roc_curve, roc_auc_score, f1_score, precision_score, recall_score)\n",
    "\n",
    "# Cross-validation and model tuning\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in CRE Data + Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv(\"data/CRE-Loan-Data.csv\")\n",
    "loans.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe info by column\n",
    "loans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats for initial numerical attributes\n",
    "loans.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaways\n",
    "- 49.2 months - the average time remaining on the dataset's loans at the time recorded\n",
    "    - longest-term existing loan is 180 months away\n",
    "- 99 months - the average loan term\n",
    "- 9.8% - the approximate percentage of loans in the dataset that defaulted within 12 months\n",
    "- 2002 - the average year of construction for properties in the dataset\n",
    "- 1.8 - the average interest coverage ratio (ICR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recasting datatypes to maximize numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Rating snapshot date' to datetime\n",
    "loans['Rating snapshot date'] = pd.to_datetime(loans['Rating snapshot date'])\n",
    "\n",
    "numericCols = ['Internal rating', 'Loan Balance', 'Interest rate', 'Property value',\n",
    "                'Net operating income', 'Interest coverage ratio', 'Original term',\n",
    "                'Months to maturity', 'Tenant turnover', 'Year of construction', 'Default flag']\n",
    "\n",
    "# Strip values of $, %, or commas and convert to numerics, also convert \"(x)\" to \"-x\"\n",
    "def cleanNumericCols(column):\n",
    "    return pd.to_numeric(column.replace({'\\$':'', ',':'', '%':'', '\\(':'-', '\\)':''}, regex=True))\n",
    "\n",
    "for col in numericCols:\n",
    "    loans[col] = cleanNumericCols(loans[col])\n",
    "\n",
    "# Convert % rate to proportion\n",
    "loans.loc[loans['Interest rate'] > 1, 'Interest rate'] /= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing new feature engineered variables `Loan-to-Value (LTV) Ratio`, `Debt Yield`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['LoanToValueRatio'] = loans['Loan Balance'] / loans['Property value']\n",
    "loans['DebtYield'] = loans['Net operating income'] / loans['Loan Balance']\n",
    "\n",
    "# Interaction Effects\n",
    "# loans['InterestCoverage-LoanBalance'] = loans['Interest coverage ratio'] * loans['Loan Balance']\n",
    "# loans['InterestRate-PropertyValue'] = loans['Interest rate'] * loans['Property value']\n",
    "\n",
    "# Drop rows with infinite values (in case of division by zero)\n",
    "loans.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "loans.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default rate by internal rating\n",
    "loans.pivot_table(index=['Internal rating'], values='Default flag', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate & Visualize Default Rate by Internal Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = loans.groupby('Internal rating')['Default flag'].agg(['count', 'sum', 'mean']).reset_index()\n",
    "grouped = grouped.rename(columns={'count': 'Number of Loans', \n",
    "                                  'sum': 'Number of Defaults', 'mean': 'Default Rate'})\n",
    "\n",
    "# grouped.loc[grouped['Default Rate'] < 1, 'Default Rate'] *= 100\n",
    "grouped['Default Rate'] = grouped['Default Rate'].round(3)\n",
    "# grouped.to_excel('riskRating-default.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot default rate by internal rating\n",
    "fig = px.bar(grouped, x='Internal rating', y='Default Rate',\n",
    "             title='Default Rate by Internal Rating', text='Default Rate')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the exception of an observed decrease in default rate between loans rated at a 4 and 5, higher internal credit risk ratings seem to correspond to higher default rates, as is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve and AUC for internal rating\n",
    "fpr, tpr, thresholds = roc_curve(loans['Default flag'], loans['Internal rating'])\n",
    "auc = roc_auc_score(loans['Default flag'], loans['Internal rating'])\n",
    "\n",
    "# GenAI created ROC curve\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'ROC curve (AUC = {auc:.2f})'))\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', name='Baseline (Random Guess)', line=dict(dash='dash')))\n",
    "fig.update_layout(title='ROC Curve for Internal Rating',\n",
    "                  xaxis_title='False Positive Rate',\n",
    "                  yaxis_title='True Positive Rate',\n",
    "                  showlegend=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate correlation with `Internal rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loansNumeric = loans.select_dtypes(include=[np.number])\n",
    "\n",
    "corrMatrix = loansNumeric.corr()\n",
    "\n",
    "corrWithRating = corrMatrix['Internal rating'].sort_values(ascending=False)\n",
    "corrWithRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlation with internal rating\n",
    "corrDF = corrWithRating.drop('Internal rating').reset_index()\n",
    "corrDF.columns = ['Feature', 'Correlation']\n",
    "corrDF['Correlation'] = np.round(corrDF['Correlation'], 3)\n",
    "\n",
    "fig = px.bar(corrDF, x='Feature', y='Correlation',\n",
    "             title='Correlation with Internal Rating', \n",
    "             )\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest regression on `Internal Rating` with dataset's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xrating = loans.drop(['Internal rating', 'Default flag', \n",
    "                      'Facility ID', 'Rating snapshot date', 'Portfolio'], axis=1)\n",
    "yrating = loans['Internal rating']\n",
    "\n",
    "categoricalFeatures = ['Property type']\n",
    "numericalFeatures = [col for col in Xrating.columns if col not in categoricalFeatures]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numericalTransformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categoricalTransformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessorRating = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numericalTransformer, numericalFeatures),\n",
    "        ('cat', categoricalTransformer, categoricalFeatures)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = Pipeline(steps=[('preprocessor', preprocessorRating),\n",
    "                            ('regressor', RandomForestRegressor(random_state=123))])\n",
    "\n",
    "regressor.fit(Xrating, yrating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine & Plot Feature Importances for Regression on `Internal Rating`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNamesCat = regressor.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categoricalFeatures)\n",
    "featureNames = np.concatenate([numericalFeatures, featureNamesCat])\n",
    "\n",
    "importances = regressor.named_steps['regressor'].feature_importances_\n",
    "featureImportances = pd.Series(importances, index=featureNames).sort_values(ascending=False)\n",
    "np.round(featureImportances * 100, 3).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances\n",
    "importanceDf = featureImportances.reset_index()\n",
    "importanceDf.columns = ['Feature', 'Importance']\n",
    "importanceDf['Importance'] = np.round(importanceDf['Importance'], 3)\n",
    "\n",
    "fig = px.bar(importanceDf.head(10), x='Feature', y='Importance',\n",
    "             title='Top 10 Feature Importances for Internal Rating', \n",
    "             )\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 3 factors influencing the internal rating:\n",
    "1. **Interest Coverage Ratio**: 66.8% importance\n",
    "2. **Property Value**: 8.3% importance\n",
    "3. **Loan Balance**: 6.7% importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive model on `Default Flag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable\n",
    "X = loans.drop(['Default flag', 'Facility ID', 'Rating snapshot date', 'Portfolio'], axis=1)\n",
    "y = loans['Default flag']\n",
    "\n",
    "# Categorical and numerical features\n",
    "categoricalFeatures = ['Property type']\n",
    "numericalFeatures = [col for col in X.columns if col not in categoricalFeatures + ['Internal rating']]\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipelines\n",
    "numericalTransformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categoricalTransformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numericalTransformer, numericalFeatures + ['Internal rating']),\n",
    "        ('cat', categoricalTransformer, categoricalFeatures)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "pipelineLR = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('classifier', LogisticRegression(max_iter=1000))])\n",
    "\n",
    "pipelineLR.fit(Xtrain, ytrain)\n",
    "\n",
    "# Predict probabilities and compute AUC for Logistic Regression\n",
    "yPredProbaLR = pipelineLR.predict_proba(Xtest)[:,1]\n",
    "aucLR = roc_auc_score(ytest, yPredProbaLR)\n",
    "print(f'Logistic Regression AUC: {aucLR:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-learn Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineGB = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('classifier', GradientBoostingClassifier(random_state=42))])\n",
    "pipelineGB.fit(Xtrain, ytrain)\n",
    "yPredProbaGB = pipelineGB.predict_proba(Xtest)[:,1]\n",
    "\n",
    "scoresGB = cross_val_score(pipelineGB, Xtrain, ytrain, cv=5, scoring='roc_auc')\n",
    "print(f'Gradient Boosting CV AUC: {np.mean(scoresGB):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineXGB = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', XGBClassifier(eval_metric='logloss', random_state=42))])\n",
    "pipelineXGB.fit(Xtrain, ytrain)\n",
    "yPredProbaXGB = pipelineXGB.predict_proba(Xtest)[:,1]\n",
    "\n",
    "scoresXGB = cross_val_score(pipelineXGB, Xtrain, ytrain, cv=5, scoring='roc_auc')\n",
    "print(f'XGBoost CV AUC: {np.mean(scoresXGB):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline (`Internal Rating`) ROC-AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute AUC for Internal Rating on test set\n",
    "ratingTest = Xtest['Internal rating']\n",
    "aucInternal = roc_auc_score(ytest, ratingTest)\n",
    "print(f'Internal Rating AUC: {aucInternal:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the results\n",
    "modelResults = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Gradient Boosting', 'XGBoost'],\n",
    "    'CV AUC': [np.mean(aucLR), np.mean(scoresGB), np.mean(scoresXGB)]\n",
    "}).set_index('Model')\n",
    "\n",
    "print(modelResults.sort_values(by='CV AUC', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning on highest performing (by ROC-AUC) models: `Logistic Regression`, `Scikit-Learn Gradient Boosting`, & `XGBoost`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridLR = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l2'],\n",
    "    'classifier__solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "\n",
    "gridSearchLR = GridSearchCV(pipelineLR, paramGridLR, cv=5, scoring='roc_auc')\n",
    "gridSearchLR.fit(Xtrain, ytrain)\n",
    "\n",
    "print(f'Best Logistic Regression AUC: {gridSearchLR.best_score_:.4f}')\n",
    "print(f'Best Parameters: {gridSearchLR.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridGB = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "    'classifier__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "gridSearchGB = GridSearchCV(pipelineGB, paramGridGB, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "gridSearchGB.fit(Xtrain, ytrain)\n",
    "\n",
    "print(f'Best Gradient Boosting AUC: {gridSearchGB.best_score_:.4f}')\n",
    "print(f'Best Parameters: {gridSearchGB.best_params_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGridXGB = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1],\n",
    "    'classifier__max_depth': [3, 5],\n",
    "    'classifier__subsample': [0.8, 1]\n",
    "}\n",
    "\n",
    "gridSearchXGB = GridSearchCV(pipelineXGB, paramGridXGB, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "gridSearchXGB.fit(Xtrain, ytrain)\n",
    "\n",
    "print(f'Best XGBoost AUC: {gridSearchXGB.best_score_:.4f}')\n",
    "print(f'Best Parameters: {gridSearchXGB.best_params_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimized models for `LR`, `GB`, and `XGB` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipelineLR = gridSearchLR.best_estimator_\n",
    "yPredProbaLR = bestPipelineLR.predict_proba(Xtest)[:, 1]\n",
    "aucLR = roc_auc_score(ytest, yPredProbaLR)\n",
    "print(f'Logistic Regression Test AUC: {aucLR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipelineGB = gridSearchGB.best_estimator_\n",
    "yPredProbaGB = bestPipelineGB.predict_proba(Xtest)[:, 1]\n",
    "aucGB = roc_auc_score(ytest, yPredProbaGB)\n",
    "print(f'Gradient Boosting Test AUC: {aucGB:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestPipelineXGB = gridSearchXGB.best_estimator_\n",
    "yPredProbaXGB = bestPipelineXGB.predict_proba(Xtest)[:, 1]\n",
    "aucXGB = roc_auc_score(ytest, yPredProbaXGB)\n",
    "print(f'XGBoost Test AUC: {aucXGB:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fprLR, tprLR, _ = roc_curve(ytest, yPredProbaLR)\n",
    "fprGB, tprGB, _ = roc_curve(ytest, yPredProbaGB)\n",
    "fprXGB, tprXGB, _ = roc_curve(ytest, yPredProbaXGB)\n",
    "fprInternal, tprInternal, _ = roc_curve(ytest, Xtest['Internal rating'])\n",
    "\n",
    "# Plot ROC curves\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fprInternal, y=tprInternal, mode='lines', name='Internal Rating'))\n",
    "fig.add_trace(go.Scatter(x=fprLR, y=tprLR, mode='lines', name='Logistic Regression'))\n",
    "fig.add_trace(go.Scatter(x=fprGB, y=tprGB, mode='lines', name='Scikit-Learn Gradient Boosting'))\n",
    "fig.add_trace(go.Scatter(x=fprXGB, y=tprXGB, mode='lines', name='XGBoost'))\n",
    "fig.add_trace(go.Scatter(x=[0,1], y=[0,1], mode='lines', name='Baseline (Random Guess)', line=dict(dash='dash')))\n",
    "fig.update_layout(title='ROC Curves Comparison',\n",
    "                  xaxis_title='False Positive Rate',\n",
    "                  yaxis_title='True Positive Rate',\n",
    "                  showlegend=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureNamesNum = numericalFeatures + ['Internal rating']\n",
    "featureNamesCat = (bestPipelineXGB.named_steps['preprocessor'].named_transformers_['cat']\n",
    "                   .named_steps['onehot'].get_feature_names_out(categoricalFeatures))\n",
    "featureNames = np.concatenate([featureNamesNum, featureNamesCat])\n",
    "\n",
    "importancesXGB = bestPipelineXGB.named_steps['classifier'].feature_importances_\n",
    "featureImportancesXGB = pd.Series(importancesXGB, index=featureNames).sort_values(ascending=False)\n",
    "\n",
    "featureImportancesXGB.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importances from final XGBoost model\n",
    "importanceXGBdf = featureImportancesXGB.reset_index()\n",
    "importanceXGBdf.columns = ['Feature', 'Importance']\n",
    "importanceXGBdf['Importance'] = np.round(importanceXGBdf['Importance'], 3)\n",
    "\n",
    "fig = px.bar(importanceXGBdf.head(10), x='Feature', y='Importance',\n",
    "             title='Top 10 Feature Importances from Optimized XGB Classifier Model', text=\"Importance\")\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()\n",
    "importanceXGBdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "- `XGBoost's Gradient Boosting Classifier` with tuned parameters achieves the highest AUC on the test set.\n",
    "- `Internal rating` is the highest importance predictor for the optimized XGB classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
